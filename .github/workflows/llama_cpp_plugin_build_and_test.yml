name: llama_cpp_plugin_build_and_test

on:
  pull_request:
    paths:
      - 'modules/llama_cpp_plugin/**'

jobs:
  build_ubuntu20:
    runs-on: ubuntu-20.04-8-cores
    steps:
      - name: Setup cmake
        uses: jwlawson/actions-setup-cmake@v1.14
        with:
          cmake-version: '3.24.x'

      - name: Checkout openvino_contrib
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: openvino_contrib

      - name: Checkout openvino
        uses: actions/checkout@v4
        with:
          submodules: recursive
          repository: openvinotoolkit/openvino
          path: openvino
          ref: releases/2024/1

      - name: CMake - configure
        run: cmake -B build -DCMAKE_BUILD_TYPE=Release -DOPENVINO_EXTRA_MODULES=${{ github.workspace }}/openvino_contrib/modules/llama_cpp_plugin -DENABLE_TESTS=ON -DENABLE_FUNCTIONAL_TESTS=ON -DENABLE_PLUGINS_XML=ON -DENABLE_LLAMA_CPP_PLUGIN_REGISTRATION=ON openvino

      - name: CMake - build
        run: cmake --build build -j`nproc` -- llama_cpp_plugin llama_cpp_e2e_tests


      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build_artifacts
          path: ${{ github.workspace }}/openvino/bin/intel64/Release/

  test_ubuntu20:
    needs: build_ubuntu20
    runs-on: ubuntu-20.04
    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build_artifacts
          path: ${{ github.workspace }}/binaries

      - name: Prepare test data - checkout llama.cpp repo
        uses: actions/checkout@v4
        with:
          repository: ggerganov/llama.cpp
          path: llama.cpp

      - name: Prepare test data - convert test model files
        run: |
          pip install -r llama.cpp/requirements/requirements-convert-hf-to-gguf.txt
          huggingface-cli download gpt2 model.safetensors tokenizer.json tokenizer_config.json vocab.json config.json merges.txt --local-dir hf_gpt2
          mkdir -p ${{ github.workspace }}/test_data
          python3 llama.cpp/convert-hf-to-gguf.py hf_gpt2 --outtype f32 --outfile ${{ github.workspace }}/test_data/gpt2.gguf

      - name: Install libtbb2
        run: |
          wget https://storage.openvinotoolkit.org/dependencies/thirdparty/linux/oneapi-tbb-2021.2.4-lin.tgz
          mkdir -p tbb
          tar xvzf oneapi-tbb-2021.2.4-lin.tgz

      - name: Run E2E tests
        run: |
          chmod +x ${{ github.workspace }}/binaries/llama_cpp_e2e_tests
          export LD_LIBRARY_PATH=${{ github.workspace }}/binaries:${{ github.workspace }}/tbb/lib
          ${{ github.workspace }}/binaries/llama_cpp_e2e_tests
